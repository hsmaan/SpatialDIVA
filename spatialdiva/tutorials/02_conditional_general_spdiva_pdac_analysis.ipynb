{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll perform conditional generation using the SpatialDIVA model, on the pancreatic cancer data from Zhou et al.\n",
    "\n",
    "The results of this analysis will be a bit different from the paper result, as we'll only use 1000 samples (spots) for quick inference and demonstration purposes, and train the full model on a subset of the data (2 slides).\n",
    "\n",
    "The high level and detailed processes for performing conditional generation is outlined in the manuscript. In general:\n",
    "\n",
    "- We start by training the SpatialDIVA model on the data.\n",
    "- We then use the trained model to generate latent samples for each of the factors we're considering.\n",
    "- We zero out all but one of the factors, and generate samples considering only the variation of the remaining factor.\n",
    "\n",
    "After this, we'll have generated transcriptomic counts specific to each factor, and we can perform additional downstream analyses, such as differential expression analysis, clustering, etc.\n",
    "\n",
    "Let's start by loading the required libraries and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys \n",
    "import os \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc \n",
    "import anndata as ann \n",
    "\n",
    "from api import StDIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first two slides of the Zhou et al dataset\n",
    "adata_path = \"/projects/scDisent/adata_tumor\"\n",
    "adata_files = [f for f in os.listdir(adata_path) if f.endswith(\".h5ad\")]\n",
    "adata_files = [os.path.join(adata_path, f) for f in adata_files]\n",
    "\n",
    "adata_files_sub = adata_files[:2]\n",
    "adatas = []\n",
    "for adata_file in adata_files_sub:\n",
    "    adata = sc.read_h5ad(adata_file)\n",
    "    adatas.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "counts_dim = adata.shape[1] # Because we are using all the genes\n",
    "uni_cols = [col for col in adatas[0].obs.columns if \"UNI\" in col]\n",
    "hist_dim = len(uni_cols)\n",
    "# When getting unique values, combine the celltypes from both slides\n",
    "y1_dim = len(np.unique(np.concatenate([adatas[0].obs[\"ST_celltype\"].values, adatas[1].obs[\"ST_celltype\"].values])))\n",
    "y2_dim = 100 # 50 PCs for the ST data and 50 PCs for the UNI data - neighbourhood context \n",
    "\n",
    "# Transform path labels due to string encoding and character issues\n",
    "# When getting unique values, combine the pathologist annotations from both slides\n",
    "path_labels = np.concatenate([adatas[0].obs[\"is_tumor\"].values, adatas[1].obs[\"is_tumor\"].values]) \n",
    "le = LabelEncoder()\n",
    "path_labels = le.fit_transform(path_labels)\n",
    "\n",
    "y3_dim = len(np.unique(path_labels))\n",
    "d_dim = 2 # For two slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdiva = StDIVA(\n",
    "    counts_dim = counts_dim,\n",
    "    hist_dim = hist_dim,\n",
    "    y1_dim = y1_dim,\n",
    "    y2_dim = y2_dim,\n",
    "    y3_dim = y3_dim,\n",
    "    d_dim = d_dim,\n",
    "    betas = [1, 1, 1, 1, 1, 1] # Default betas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders..\n"
     ]
    }
   ],
   "source": [
    "stdiva.add_data(\n",
    "    adata = adata_files[0:2],\n",
    "    label_key_y1 = \"ST_celltype\",\n",
    "    label_key_y3 = \"is_tumor\",\n",
    "    hist_col_key = \"UNI\",\n",
    "    hvg = False # We are not using HVGs - we are using all the genes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000,  0.0000,  0.0000,  ...,  1.4588, -0.9544, -0.8738],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.6525,  1.4684, -0.7221],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.9315,  1.6959,  0.0036],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.4829, -0.7341,  0.2258],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -1.1429, -0.4445,  1.6168],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -1.1215,  1.5875,  1.6937]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[-2.1983e+03, -1.6429e+01,  2.6632e+01,  ...,  3.7452e-01,\n",
       "          -7.3386e-01,  1.6814e-01],\n",
       "         [-1.3133e+02,  1.4320e+01,  2.0774e+00,  ..., -6.1705e-01,\n",
       "          -2.4862e-02,  1.1912e-01],\n",
       "         [-2.3178e+03, -5.9742e+01, -5.6596e+01,  ..., -2.4519e-01,\n",
       "          -1.4641e+00,  3.3673e-01],\n",
       "         ...,\n",
       "         [-2.1925e+03, -5.7985e+01, -4.1925e+01,  ..., -1.6456e+00,\n",
       "          -1.1856e-01, -5.5584e-01],\n",
       "         [-1.4214e+02,  2.5372e+01,  9.3722e-02,  ...,  4.6355e-01,\n",
       "          -2.7082e-01,  1.9283e-01],\n",
       "         [-2.9736e+02, -4.9850e+01, -9.5930e+00,  ..., -6.2540e-01,\n",
       "          -1.6570e-01, -4.1848e-01]]),\n",
       " tensor([[1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.]], dtype=torch.float64),\n",
       " tensor([[ 7046, 15181],\n",
       "         [10985, 15761],\n",
       "         [ 8300,  2022],\n",
       "         [ 8527,  5621],\n",
       "         [13990, 10287],\n",
       "         [ 6630,  6091],\n",
       "         [14176, 16772],\n",
       "         [11828,  9798],\n",
       "         [ 8384, 13535],\n",
       "         [12704, 13024],\n",
       "         [10691,  7103],\n",
       "         [13761,  6439],\n",
       "         [10960,  8808],\n",
       "         [16746,  9814],\n",
       "         [10302,  5954],\n",
       "         [16078,  3239],\n",
       "         [ 9877,  7943],\n",
       "         [17161,  4353],\n",
       "         [16362,  8913],\n",
       "         [10079,  3844],\n",
       "         [ 5761,  4853],\n",
       "         [13773,  9916],\n",
       "         [ 7027,  9224],\n",
       "         [15302, 14753],\n",
       "         [ 8778, 16664],\n",
       "         [ 7701,  3480],\n",
       "         [11822,  8060],\n",
       "         [12015, 16282],\n",
       "         [ 7260, 14808],\n",
       "         [ 1836,  6262],\n",
       "         [15293, 12021],\n",
       "         [ 8561, 16293],\n",
       "         [10912,  8467],\n",
       "         [13319,  3709],\n",
       "         [13142, 14760],\n",
       "         [17444,  9282],\n",
       "         [10548, 14521],\n",
       "         [10906,  6730],\n",
       "         [ 5718,  5009],\n",
       "         [12037,  7687],\n",
       "         [ 8351,  3850],\n",
       "         [ 6604, 11955],\n",
       "         [15056,  6186],\n",
       "         [10938, 16906],\n",
       "         [ 3182,  8587],\n",
       "         [ 4207,  4889],\n",
       "         [12045, 10170],\n",
       "         [ 7055,  4103],\n",
       "         [ 6161,  8482],\n",
       "         [ 6201,  7086],\n",
       "         [15055,  5689],\n",
       "         [ 5781, 10564],\n",
       "         [ 4692,  7961],\n",
       "         [ 9621,  9961],\n",
       "         [10734,  5705],\n",
       "         [ 5353, 11559],\n",
       "         [15086, 14629],\n",
       "         [16523,  7705],\n",
       "         [13334,  7931],\n",
       "         [ 6165,  9723],\n",
       "         [12273, 13522],\n",
       "         [ 9438,  5957],\n",
       "         [13513, 11686],\n",
       "         [14007, 15006],\n",
       "         [ 3164,  3372],\n",
       "         [13919,  3494],\n",
       "         [ 5731,  8980],\n",
       "         [17456, 12759],\n",
       "         [17379,  5221],\n",
       "         [13513, 11934],\n",
       "         [ 8749,  7481],\n",
       "         [ 8829, 17010],\n",
       "         [12195,  4492],\n",
       "         [16944,  4229],\n",
       "         [10483,  9461],\n",
       "         [ 6871, 13168],\n",
       "         [ 8612, 16887],\n",
       "         [15726, 12268],\n",
       "         [13368, 17615],\n",
       "         [ 5992,  8950],\n",
       "         [ 2961,  7222],\n",
       "         [ 4651,  8859],\n",
       "         [10256,  6112],\n",
       "         [ 6837, 17539],\n",
       "         [ 7259, 14311],\n",
       "         [15502, 10158],\n",
       "         [ 4224, 10598],\n",
       "         [ 4483, 10072],\n",
       "         [ 5778,  9571],\n",
       "         [16145,  8542],\n",
       "         [11980,  4865],\n",
       "         [ 3781,  6876],\n",
       "         [13786, 13641],\n",
       "         [ 9616,  8471],\n",
       "         [ 7257, 13815],\n",
       "         [ 4213,  7123],\n",
       "         [15711,  8046],\n",
       "         [ 5531, 14068],\n",
       "         [12008, 13800],\n",
       "         [10894,  2759],\n",
       "         [ 4048,  9080],\n",
       "         [14828,  2586],\n",
       "         [ 4482,  9824],\n",
       "         [16760, 14282],\n",
       "         [ 5561,  9448],\n",
       "         [15267,  4571],\n",
       "         [12842,  4366],\n",
       "         [14640, 10658],\n",
       "         [14390, 16151],\n",
       "         [ 4212,  6627],\n",
       "         [ 8786,  4842],\n",
       "         [13336,  8427],\n",
       "         [ 6392, 13321],\n",
       "         [ 4864,  7990],\n",
       "         [16344,  3698],\n",
       "         [11591,  3715],\n",
       "         [12934, 17120],\n",
       "         [10514,  4836],\n",
       "         [15727, 12516],\n",
       "         [16605, 16487],\n",
       "         [10717, 15293],\n",
       "         [ 5757,  3611],\n",
       "         [15690, 17388],\n",
       "         [12707, 14017],\n",
       "         [ 6829, 15057],\n",
       "         [15455, 11308],\n",
       "         [ 9022, 10429],\n",
       "         [12220, 12683]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(stdiva.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialdiva-PyiMLd3V-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
