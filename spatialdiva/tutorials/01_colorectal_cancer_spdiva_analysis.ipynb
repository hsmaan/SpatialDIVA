{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up autoreload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll train the SpatialDIVA model on the Valdeolivas et al. colorectal cancer dataset, comprising of 12 slides of colorectal cancer tissue from different patients.\n",
    "\n",
    "For demonstration, we'll restrict the data to two slides for training of the model. After training, we'll extract embeddings from the different latent subspaces of SpatialDIVA, and analyze their covariance. We'll also examine how SpatialDIVA performs in terms of batch correction.\n",
    "\n",
    "We'll use the high-level SpatialDIVA API to train the model and extract embeddings.\n",
    "\n",
    "Let's start by loading the necessary modules and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc \n",
    "import anndata as ann \n",
    "\n",
    "from api import StDIVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by loading the anndata objects for Valdeolivas et al - in this case we'll restrict it to the first two files, corresponding to two slides.\n",
    "\n",
    "This data has been preprocessed such that spot-level deconvolution has been done, and pathologist annotations are also present in the data. UNI-feature extraction for the spot-level histpathology patches corresponding to the ST spots, has also been done. The appropriate features are stored in the `.obs` attribute of the anndata object, with the identifiers \"UNI\" before the feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first two slides of the Valdeolivas et al dataset\n",
    "adata_path = \"/scratch/hdd001/home/hmaan/visium_datasets/valdeolivas_hest_data\"\n",
    "adata_files = [f for f in os.listdir(adata_path) if f.endswith(\"processed.h5ad\")]\n",
    "adata_files = [os.path.join(adata_path, f) for f in adata_files]\n",
    "\n",
    "adata_files_sub = adata_files[:2]\n",
    "adatas = []\n",
    "for adata_file in adata_files_sub:\n",
    "    adata = sc.read_h5ad(adata_file)\n",
    "    adatas.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['array_row_x', 'array_col_x', 'pxl_col_in_fullres',\n",
       "       'pxl_row_in_fullres', 'in_tissue_x', 'pxl_row_in_fullres_old',\n",
       "       'pxl_col_in_fullres_old', 'n_genes_by_counts_x',\n",
       "       'log1p_n_genes_by_counts_x', 'total_counts_x',\n",
       "       ...\n",
       "       'UNI-1015', 'UNI-1016', 'UNI-1017', 'UNI-1018', 'UNI-1019', 'UNI-1020',\n",
       "       'UNI-1021', 'UNI-1022', 'UNI-1023', 'UNI-1024'],\n",
       "      dtype='object', length=1348)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas[0].obs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the UNI columns are at the end of the anndata obs attributes, followed by the other metadata. The format of this anndata object is such that each spot corresponds to one observation.\n",
    "\n",
    "The pathologist annotations per spot are stored in `.obs[\"Pathologist Annotation]`\n",
    "\n",
    "The maximally represented cell-type (after deconvolution) per spot is stored in `.obs[\"ST_celltype\"]`\n",
    "\n",
    "The batch/sample label is stored in `.obs[\"sample\"]`\n",
    "\n",
    "The positions of each spot on the slide are stored in `.obsm[\"spatial\"]`\n",
    "\n",
    "We'll need the following information for SpatialDIVA training - \n",
    "\n",
    "- The dimensionality of the UNI features\n",
    "- The dimensionality of the pathologist annotations (total number of classes)\n",
    "- The dimensionality of the batch/sample labels (total number of classes)\n",
    "- The dimensionality of the ST celltypes (total number of classes)\n",
    "- The dimensionality of the neighborhood context for each spot (50 dimensional by default)\n",
    "\n",
    "Let's go ahead and extract those from the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "counts_dim = 2500 # Because we are using 2500 HVGS in the processor later \n",
    "uni_cols = [col for col in adatas[0].obs.columns if \"UNI\" in col]\n",
    "hist_dim = len(uni_cols)\n",
    "y1_dim = len(np.unique(adatas[0].obs[\"ST_celltype\"].values))\n",
    "y2_dim = 50\n",
    "\n",
    "# Transform path labels due to string encoding and character issues\n",
    "path_labels = adatas[0].obs[\"Pathologist Annotation\"].values\n",
    "le = LabelEncoder()\n",
    "path_labels = le.fit_transform(path_labels)\n",
    "\n",
    "y3_dim = len(np.unique(path_labels))\n",
    "d_dim = 2 # For two slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the data further here, or load it into the StDIVA API. This API will also take in the file locations, and perform relevant preprocessing steps (using the function `adata_process` - more information in the documentation). The API will also perform the training of the model, and extraction of embeddings.\n",
    "\n",
    "Let's go ahead and initialize the SpatialDIVA API with the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdiva = StDIVA(\n",
    "    counts_dim = counts_dim,\n",
    "    hist_dim = hist_dim,\n",
    "    y1_dim = y1_dim,\n",
    "    y2_dim = y2_dim,\n",
    "    y3_dim = y3_dim,\n",
    "    d_dim = d_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the data to the API in the form of a list of files corresponding to the anndata object with the information we've outlined above. \n",
    "\n",
    "We'll use 90% of the combined slides for training, and 10% for validation (the default split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/storage.py:85: ImplicitModificationWarning: X should not be a np.matrix, use np.ndarray instead.\n",
      "  warnings.warn(msg, ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "stdiva.add_data(\n",
    "    adata = adata_files[0:2],\n",
    "    label_key_y1 = \"ST_celltype\",\n",
    "    label_key_y3 = \"Pathologist Annotation\",\n",
    "    hist_col_key = \"UNI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can go ahead and train the model. The default number of epochs is 100, with early stopping enabled by default. Let's use these parameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-Pyi ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params | Mode\n",
      "---------------------------------------------\n",
      "0 | model | SpatialDIVA | 3.3 M  | eval\n",
      "---------------------------------------------\n",
      "3.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 M     Total params\n",
      "13.148    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "110       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9dfb2ba5c34757a6479e0d91dd8766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x37625 and 3524x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstdiva\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs01/home/hmaan/Documents/SpatialDIVA/spatialdiva/tutorials/../api/st_diva_api.py:241\u001b[0m, in \u001b[0;36mStDIVA.train\u001b[0;34m(self, max_epochs, early_stopping, patience)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Train the model using torch lightning \u001b[39;00m\n\u001b[1;32m    237\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    238\u001b[0m     max_epochs \u001b[38;5;241m=\u001b[39m max_epochs,\n\u001b[1;32m    239\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience)] \u001b[38;5;28;01mif\u001b[39;00m early_stopping \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    240\u001b[0m )\n\u001b[0;32m--> 241\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:1024\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1024\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1026\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1050\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:144\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:433\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    427\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    432\u001b[0m )\n\u001b[0;32m--> 433\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:323\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 323\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    326\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs01/home/hmaan/Documents/SpatialDIVA/spatialdiva/tutorials/../models/diva_spatial.py:1090\u001b[0m, in \u001b[0;36mLitSpatialDIVA.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1083\u001b[0m     y \u001b[38;5;241m=\u001b[39m [y1, y2, y3]\n\u001b[1;32m   1085\u001b[0m (\n\u001b[1;32m   1086\u001b[0m     px_mu_gauss, px_logvar_gauss, px_mu_nb, px_theta_nb,\n\u001b[1;32m   1087\u001b[0m     pzd_loc, pzd_logvar, pzy_locs, pzy_logvars,\n\u001b[1;32m   1088\u001b[0m     qzx_loc, qzx_logvar, qzd_loc, qzd_logvar,\n\u001b[1;32m   1089\u001b[0m     qzy_locs, qzy_logvars, qd_loc, qy_locs\n\u001b[0;32m-> 1090\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m (\n\u001b[1;32m   1093\u001b[0m     recon_loss, \n\u001b[1;32m   1094\u001b[0m     kl_zx, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1123\u001b[0m     current_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m   1124\u001b[0m )\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_recon_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, recon_loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/fs01/home/hmaan/Documents/SpatialDIVA/spatialdiva/tutorials/../models/diva_spatial.py:543\u001b[0m, in \u001b[0;36mSpatialDIVA.forward\u001b[0;34m(self, x, d, y, edge_index)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, d, y, edge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;66;03m# Encode the data\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m     qzx_loc, qzx_logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqzx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     qzd_loc, qzd_logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqzd(x)\n\u001b[1;32m    545\u001b[0m     qzy_locs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/fs01/home/hmaan/Documents/SpatialDIVA/spatialdiva/tutorials/../models/diva_spatial.py:257\u001b[0m, in \u001b[0;36mqzx.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 257\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_qzx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     mu_zx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_mu_zx(h)\n\u001b[1;32m    259\u001b[0m     logvar_zx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_logvar_zx(h)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x37625 and 3524x128)"
     ]
    }
   ],
   "source": [
    "stdiva.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 2703 × 36601\n",
       "    obs: 'array_row_x', 'array_col_x', 'pxl_col_in_fullres', 'pxl_row_in_fullres', 'in_tissue_x', 'pxl_row_in_fullres_old', 'pxl_col_in_fullres_old', 'n_genes_by_counts_x', 'log1p_n_genes_by_counts_x', 'total_counts_x', 'log1p_total_counts_x', 'pct_counts_in_top_50_genes_x', 'pct_counts_in_top_100_genes_x', 'pct_counts_in_top_200_genes_x', 'pct_counts_in_top_500_genes_x', 'total_counts_mito', 'log1p_total_counts_mito', 'pct_counts_mito', 'Pathologist Annotation', 'ST-clusters', 'source', 'leiden', 'in_tissue_y', 'array_row_y', 'array_col_y', 'sample', 'n_genes_by_counts_y', 'log1p_n_genes_by_counts_y', 'total_counts_y', 'log1p_total_counts_y', 'pct_counts_in_top_50_genes_y', 'pct_counts_in_top_100_genes_y', 'pct_counts_in_top_200_genes_y', 'pct_counts_in_top_500_genes_y', 'mt_frac', 'mean_spot_factorsCD19+CD20+ B', 'mean_spot_factorsCD4+ T cells', 'mean_spot_factorsCD8+ T cells', 'mean_spot_factorsCMS1', 'mean_spot_factorsCMS2', 'mean_spot_factorsCMS3', 'mean_spot_factorsCMS4', 'mean_spot_factorsEnteric glial cells', 'mean_spot_factorsGoblet cells', 'mean_spot_factorsIgA+ Plasma', 'mean_spot_factorsIgG+ Plasma', 'mean_spot_factorsIntermediate', 'mean_spot_factorsLymphatic ECs', 'mean_spot_factorsMast cells', 'mean_spot_factorsMature Enterocytes type 1', 'mean_spot_factorsMature Enterocytes type 2', 'mean_spot_factorsMyofibroblasts', 'mean_spot_factorsNK cells', 'mean_spot_factorsPericytes', 'mean_spot_factorsPro-inflammatory', 'mean_spot_factorsProliferating', 'mean_spot_factorsProliferative ECs', 'mean_spot_factorsRegulatory T cells', 'mean_spot_factorsSPP1+', 'mean_spot_factorsSmooth muscle cells', 'mean_spot_factorsStalk-like ECs', 'mean_spot_factorsStem-like/TA', 'mean_spot_factorsStromal 1', 'mean_spot_factorsStromal 2', 'mean_spot_factorsStromal 3', 'mean_spot_factorsT follicular helper cells', 'mean_spot_factorsT helper 17 cells', 'mean_spot_factorsTip-like ECs', 'mean_spot_factorsUnknown', 'mean_spot_factorscDC', 'mean_spot_factorsgamma delta T cells', 'sd_spot_factorsCD19+CD20+ B', 'sd_spot_factorsCD4+ T cells', 'sd_spot_factorsCD8+ T cells', 'sd_spot_factorsCMS1', 'sd_spot_factorsCMS2', 'sd_spot_factorsCMS3', 'sd_spot_factorsCMS4', 'sd_spot_factorsEnteric glial cells', 'sd_spot_factorsGoblet cells', 'sd_spot_factorsIgA+ Plasma', 'sd_spot_factorsIgG+ Plasma', 'sd_spot_factorsIntermediate', 'sd_spot_factorsLymphatic ECs', 'sd_spot_factorsMast cells', 'sd_spot_factorsMature Enterocytes type 1', 'sd_spot_factorsMature Enterocytes type 2', 'sd_spot_factorsMyofibroblasts', 'sd_spot_factorsNK cells', 'sd_spot_factorsPericytes', 'sd_spot_factorsPro-inflammatory', 'sd_spot_factorsProliferating', 'sd_spot_factorsProliferative ECs', 'sd_spot_factorsRegulatory T cells', 'sd_spot_factorsSPP1+', 'sd_spot_factorsSmooth muscle cells', 'sd_spot_factorsStalk-like ECs', 'sd_spot_factorsStem-like/TA', 'sd_spot_factorsStromal 1', 'sd_spot_factorsStromal 2', 'sd_spot_factorsStromal 3', 'sd_spot_factorsT follicular helper cells', 'sd_spot_factorsT helper 17 cells', 'sd_spot_factorsTip-like ECs', 'sd_spot_factorsUnknown', 'sd_spot_factorscDC', 'sd_spot_factorsgamma delta T cells', 'q05_spot_factorsCD19+CD20+ B', 'q05_spot_factorsCD4+ T cells', 'q05_spot_factorsCD8+ T cells', 'q05_spot_factorsCMS1', 'q05_spot_factorsCMS2', 'q05_spot_factorsCMS3', 'q05_spot_factorsCMS4', 'q05_spot_factorsEnteric glial cells', 'q05_spot_factorsGoblet cells', 'q05_spot_factorsIgA+ Plasma', 'q05_spot_factorsIgG+ Plasma', 'q05_spot_factorsIntermediate', 'q05_spot_factorsLymphatic ECs', 'q05_spot_factorsMast cells', 'q05_spot_factorsMature Enterocytes type 1', 'q05_spot_factorsMature Enterocytes type 2', 'q05_spot_factorsMyofibroblasts', 'q05_spot_factorsNK cells', 'q05_spot_factorsPericytes', 'q05_spot_factorsPro-inflammatory', 'q05_spot_factorsProliferating', 'q05_spot_factorsProliferative ECs', 'q05_spot_factorsRegulatory T cells', 'q05_spot_factorsSPP1+', 'q05_spot_factorsSmooth muscle cells', 'q05_spot_factorsStalk-like ECs', 'q05_spot_factorsStem-like/TA', 'q05_spot_factorsStromal 1', 'q05_spot_factorsStromal 2', 'q05_spot_factorsStromal 3', 'q05_spot_factorsT follicular helper cells', 'q05_spot_factorsT helper 17 cells', 'q05_spot_factorsTip-like ECs', 'q05_spot_factorsUnknown', 'q05_spot_factorscDC', 'q05_spot_factorsgamma delta T cells', 'q95_spot_factorsCD19+CD20+ B', 'q95_spot_factorsCD4+ T cells', 'q95_spot_factorsCD8+ T cells', 'q95_spot_factorsCMS1', 'q95_spot_factorsCMS2', 'q95_spot_factorsCMS3', 'q95_spot_factorsCMS4', 'q95_spot_factorsEnteric glial cells', 'q95_spot_factorsGoblet cells', 'q95_spot_factorsIgA+ Plasma', 'q95_spot_factorsIgG+ Plasma', 'q95_spot_factorsIntermediate', 'q95_spot_factorsLymphatic ECs', 'q95_spot_factorsMast cells', 'q95_spot_factorsMature Enterocytes type 1', 'q95_spot_factorsMature Enterocytes type 2', 'q95_spot_factorsMyofibroblasts', 'q95_spot_factorsNK cells', 'q95_spot_factorsPericytes', 'q95_spot_factorsPro-inflammatory', 'q95_spot_factorsProliferating', 'q95_spot_factorsProliferative ECs', 'q95_spot_factorsRegulatory T cells', 'q95_spot_factorsSPP1+', 'q95_spot_factorsSmooth muscle cells', 'q95_spot_factorsStalk-like ECs', 'q95_spot_factorsStem-like/TA', 'q95_spot_factorsStromal 1', 'q95_spot_factorsStromal 2', 'q95_spot_factorsStromal 3', 'q95_spot_factorsT follicular helper cells', 'q95_spot_factorsT helper 17 cells', 'q95_spot_factorsTip-like ECs', 'q95_spot_factorsUnknown', 'q95_spot_factorscDC', 'q95_spot_factorsgamma delta T cells', 'mean_nUMI_factorsCD19+CD20+ B', 'mean_nUMI_factorsCD4+ T cells', 'mean_nUMI_factorsCD8+ T cells', 'mean_nUMI_factorsCMS1', 'mean_nUMI_factorsCMS2', 'mean_nUMI_factorsCMS3', 'mean_nUMI_factorsCMS4', 'mean_nUMI_factorsEnteric glial cells', 'mean_nUMI_factorsGoblet cells', 'mean_nUMI_factorsIgA+ Plasma', 'mean_nUMI_factorsIgG+ Plasma', 'mean_nUMI_factorsIntermediate', 'mean_nUMI_factorsLymphatic ECs', 'mean_nUMI_factorsMast cells', 'mean_nUMI_factorsMature Enterocytes type 1', 'mean_nUMI_factorsMature Enterocytes type 2', 'mean_nUMI_factorsMyofibroblasts', 'mean_nUMI_factorsNK cells', 'mean_nUMI_factorsPericytes', 'mean_nUMI_factorsPro-inflammatory', 'mean_nUMI_factorsProliferating', 'mean_nUMI_factorsProliferative ECs', 'mean_nUMI_factorsRegulatory T cells', 'mean_nUMI_factorsSPP1+', 'mean_nUMI_factorsSmooth muscle cells', 'mean_nUMI_factorsStalk-like ECs', 'mean_nUMI_factorsStem-like/TA', 'mean_nUMI_factorsStromal 1', 'mean_nUMI_factorsStromal 2', 'mean_nUMI_factorsStromal 3', 'mean_nUMI_factorsT follicular helper cells', 'mean_nUMI_factorsT helper 17 cells', 'mean_nUMI_factorsTip-like ECs', 'mean_nUMI_factorsUnknown', 'mean_nUMI_factorscDC', 'mean_nUMI_factorsgamma delta T cells', 'sd_nUMI_factorsCD19+CD20+ B', 'sd_nUMI_factorsCD4+ T cells', 'sd_nUMI_factorsCD8+ T cells', 'sd_nUMI_factorsCMS1', 'sd_nUMI_factorsCMS2', 'sd_nUMI_factorsCMS3', 'sd_nUMI_factorsCMS4', 'sd_nUMI_factorsEnteric glial cells', 'sd_nUMI_factorsGoblet cells', 'sd_nUMI_factorsIgA+ Plasma', 'sd_nUMI_factorsIgG+ Plasma', 'sd_nUMI_factorsIntermediate', 'sd_nUMI_factorsLymphatic ECs', 'sd_nUMI_factorsMast cells', 'sd_nUMI_factorsMature Enterocytes type 1', 'sd_nUMI_factorsMature Enterocytes type 2', 'sd_nUMI_factorsMyofibroblasts', 'sd_nUMI_factorsNK cells', 'sd_nUMI_factorsPericytes', 'sd_nUMI_factorsPro-inflammatory', 'sd_nUMI_factorsProliferating', 'sd_nUMI_factorsProliferative ECs', 'sd_nUMI_factorsRegulatory T cells', 'sd_nUMI_factorsSPP1+', 'sd_nUMI_factorsSmooth muscle cells', 'sd_nUMI_factorsStalk-like ECs', 'sd_nUMI_factorsStem-like/TA', 'sd_nUMI_factorsStromal 1', 'sd_nUMI_factorsStromal 2', 'sd_nUMI_factorsStromal 3', 'sd_nUMI_factorsT follicular helper cells', 'sd_nUMI_factorsT helper 17 cells', 'sd_nUMI_factorsTip-like ECs', 'sd_nUMI_factorsUnknown', 'sd_nUMI_factorscDC', 'sd_nUMI_factorsgamma delta T cells', 'q05_nUMI_factorsCD19+CD20+ B', 'q05_nUMI_factorsCD4+ T cells', 'q05_nUMI_factorsCD8+ T cells', 'q05_nUMI_factorsCMS1', 'q05_nUMI_factorsCMS2', 'q05_nUMI_factorsCMS3', 'q05_nUMI_factorsCMS4', 'q05_nUMI_factorsEnteric glial cells', 'q05_nUMI_factorsGoblet cells', 'q05_nUMI_factorsIgA+ Plasma', 'q05_nUMI_factorsIgG+ Plasma', 'q05_nUMI_factorsIntermediate', 'q05_nUMI_factorsLymphatic ECs', 'q05_nUMI_factorsMast cells', 'q05_nUMI_factorsMature Enterocytes type 1', 'q05_nUMI_factorsMature Enterocytes type 2', 'q05_nUMI_factorsMyofibroblasts', 'q05_nUMI_factorsNK cells', 'q05_nUMI_factorsPericytes', 'q05_nUMI_factorsPro-inflammatory', 'q05_nUMI_factorsProliferating', 'q05_nUMI_factorsProliferative ECs', 'q05_nUMI_factorsRegulatory T cells', 'q05_nUMI_factorsSPP1+', 'q05_nUMI_factorsSmooth muscle cells', 'q05_nUMI_factorsStalk-like ECs', 'q05_nUMI_factorsStem-like/TA', 'q05_nUMI_factorsStromal 1', 'q05_nUMI_factorsStromal 2', 'q05_nUMI_factorsStromal 3', 'q05_nUMI_factorsT follicular helper cells', 'q05_nUMI_factorsT helper 17 cells', 'q05_nUMI_factorsTip-like ECs', 'q05_nUMI_factorsUnknown', 'q05_nUMI_factorscDC', 'q05_nUMI_factorsgamma delta T cells', 'q95_nUMI_factorsCD19+CD20+ B', 'q95_nUMI_factorsCD4+ T cells', 'q95_nUMI_factorsCD8+ T cells', 'q95_nUMI_factorsCMS1', 'q95_nUMI_factorsCMS2', 'q95_nUMI_factorsCMS3', 'q95_nUMI_factorsCMS4', 'q95_nUMI_factorsEnteric glial cells', 'q95_nUMI_factorsGoblet cells', 'q95_nUMI_factorsIgA+ Plasma', 'q95_nUMI_factorsIgG+ Plasma', 'q95_nUMI_factorsIntermediate', 'q95_nUMI_factorsLymphatic ECs', 'q95_nUMI_factorsMast cells', 'q95_nUMI_factorsMature Enterocytes type 1', 'q95_nUMI_factorsMature Enterocytes type 2', 'q95_nUMI_factorsMyofibroblasts', 'q95_nUMI_factorsNK cells', 'q95_nUMI_factorsPericytes', 'q95_nUMI_factorsPro-inflammatory', 'q95_nUMI_factorsProliferating', 'q95_nUMI_factorsProliferative ECs', 'q95_nUMI_factorsRegulatory T cells', 'q95_nUMI_factorsSPP1+', 'q95_nUMI_factorsSmooth muscle cells', 'q95_nUMI_factorsStalk-like ECs', 'q95_nUMI_factorsStem-like/TA', 'q95_nUMI_factorsStromal 1', 'q95_nUMI_factorsStromal 2', 'q95_nUMI_factorsStromal 3', 'q95_nUMI_factorsT follicular helper cells', 'q95_nUMI_factorsT helper 17 cells', 'q95_nUMI_factorsTip-like ECs', 'q95_nUMI_factorsUnknown', 'q95_nUMI_factorscDC', 'q95_nUMI_factorsgamma delta T cells', 'ST_celltype', 'UNI-1', 'UNI-2', 'UNI-3', 'UNI-4', 'UNI-5', 'UNI-6', 'UNI-7', 'UNI-8', 'UNI-9', 'UNI-10', 'UNI-11', 'UNI-12', 'UNI-13', 'UNI-14', 'UNI-15', 'UNI-16', 'UNI-17', 'UNI-18', 'UNI-19', 'UNI-20', 'UNI-21', 'UNI-22', 'UNI-23', 'UNI-24', 'UNI-25', 'UNI-26', 'UNI-27', 'UNI-28', 'UNI-29', 'UNI-30', 'UNI-31', 'UNI-32', 'UNI-33', 'UNI-34', 'UNI-35', 'UNI-36', 'UNI-37', 'UNI-38', 'UNI-39', 'UNI-40', 'UNI-41', 'UNI-42', 'UNI-43', 'UNI-44', 'UNI-45', 'UNI-46', 'UNI-47', 'UNI-48', 'UNI-49', 'UNI-50', 'UNI-51', 'UNI-52', 'UNI-53', 'UNI-54', 'UNI-55', 'UNI-56', 'UNI-57', 'UNI-58', 'UNI-59', 'UNI-60', 'UNI-61', 'UNI-62', 'UNI-63', 'UNI-64', 'UNI-65', 'UNI-66', 'UNI-67', 'UNI-68', 'UNI-69', 'UNI-70', 'UNI-71', 'UNI-72', 'UNI-73', 'UNI-74', 'UNI-75', 'UNI-76', 'UNI-77', 'UNI-78', 'UNI-79', 'UNI-80', 'UNI-81', 'UNI-82', 'UNI-83', 'UNI-84', 'UNI-85', 'UNI-86', 'UNI-87', 'UNI-88', 'UNI-89', 'UNI-90', 'UNI-91', 'UNI-92', 'UNI-93', 'UNI-94', 'UNI-95', 'UNI-96', 'UNI-97', 'UNI-98', 'UNI-99', 'UNI-100', 'UNI-101', 'UNI-102', 'UNI-103', 'UNI-104', 'UNI-105', 'UNI-106', 'UNI-107', 'UNI-108', 'UNI-109', 'UNI-110', 'UNI-111', 'UNI-112', 'UNI-113', 'UNI-114', 'UNI-115', 'UNI-116', 'UNI-117', 'UNI-118', 'UNI-119', 'UNI-120', 'UNI-121', 'UNI-122', 'UNI-123', 'UNI-124', 'UNI-125', 'UNI-126', 'UNI-127', 'UNI-128', 'UNI-129', 'UNI-130', 'UNI-131', 'UNI-132', 'UNI-133', 'UNI-134', 'UNI-135', 'UNI-136', 'UNI-137', 'UNI-138', 'UNI-139', 'UNI-140', 'UNI-141', 'UNI-142', 'UNI-143', 'UNI-144', 'UNI-145', 'UNI-146', 'UNI-147', 'UNI-148', 'UNI-149', 'UNI-150', 'UNI-151', 'UNI-152', 'UNI-153', 'UNI-154', 'UNI-155', 'UNI-156', 'UNI-157', 'UNI-158', 'UNI-159', 'UNI-160', 'UNI-161', 'UNI-162', 'UNI-163', 'UNI-164', 'UNI-165', 'UNI-166', 'UNI-167', 'UNI-168', 'UNI-169', 'UNI-170', 'UNI-171', 'UNI-172', 'UNI-173', 'UNI-174', 'UNI-175', 'UNI-176', 'UNI-177', 'UNI-178', 'UNI-179', 'UNI-180', 'UNI-181', 'UNI-182', 'UNI-183', 'UNI-184', 'UNI-185', 'UNI-186', 'UNI-187', 'UNI-188', 'UNI-189', 'UNI-190', 'UNI-191', 'UNI-192', 'UNI-193', 'UNI-194', 'UNI-195', 'UNI-196', 'UNI-197', 'UNI-198', 'UNI-199', 'UNI-200', 'UNI-201', 'UNI-202', 'UNI-203', 'UNI-204', 'UNI-205', 'UNI-206', 'UNI-207', 'UNI-208', 'UNI-209', 'UNI-210', 'UNI-211', 'UNI-212', 'UNI-213', 'UNI-214', 'UNI-215', 'UNI-216', 'UNI-217', 'UNI-218', 'UNI-219', 'UNI-220', 'UNI-221', 'UNI-222', 'UNI-223', 'UNI-224', 'UNI-225', 'UNI-226', 'UNI-227', 'UNI-228', 'UNI-229', 'UNI-230', 'UNI-231', 'UNI-232', 'UNI-233', 'UNI-234', 'UNI-235', 'UNI-236', 'UNI-237', 'UNI-238', 'UNI-239', 'UNI-240', 'UNI-241', 'UNI-242', 'UNI-243', 'UNI-244', 'UNI-245', 'UNI-246', 'UNI-247', 'UNI-248', 'UNI-249', 'UNI-250', 'UNI-251', 'UNI-252', 'UNI-253', 'UNI-254', 'UNI-255', 'UNI-256', 'UNI-257', 'UNI-258', 'UNI-259', 'UNI-260', 'UNI-261', 'UNI-262', 'UNI-263', 'UNI-264', 'UNI-265', 'UNI-266', 'UNI-267', 'UNI-268', 'UNI-269', 'UNI-270', 'UNI-271', 'UNI-272', 'UNI-273', 'UNI-274', 'UNI-275', 'UNI-276', 'UNI-277', 'UNI-278', 'UNI-279', 'UNI-280', 'UNI-281', 'UNI-282', 'UNI-283', 'UNI-284', 'UNI-285', 'UNI-286', 'UNI-287', 'UNI-288', 'UNI-289', 'UNI-290', 'UNI-291', 'UNI-292', 'UNI-293', 'UNI-294', 'UNI-295', 'UNI-296', 'UNI-297', 'UNI-298', 'UNI-299', 'UNI-300', 'UNI-301', 'UNI-302', 'UNI-303', 'UNI-304', 'UNI-305', 'UNI-306', 'UNI-307', 'UNI-308', 'UNI-309', 'UNI-310', 'UNI-311', 'UNI-312', 'UNI-313', 'UNI-314', 'UNI-315', 'UNI-316', 'UNI-317', 'UNI-318', 'UNI-319', 'UNI-320', 'UNI-321', 'UNI-322', 'UNI-323', 'UNI-324', 'UNI-325', 'UNI-326', 'UNI-327', 'UNI-328', 'UNI-329', 'UNI-330', 'UNI-331', 'UNI-332', 'UNI-333', 'UNI-334', 'UNI-335', 'UNI-336', 'UNI-337', 'UNI-338', 'UNI-339', 'UNI-340', 'UNI-341', 'UNI-342', 'UNI-343', 'UNI-344', 'UNI-345', 'UNI-346', 'UNI-347', 'UNI-348', 'UNI-349', 'UNI-350', 'UNI-351', 'UNI-352', 'UNI-353', 'UNI-354', 'UNI-355', 'UNI-356', 'UNI-357', 'UNI-358', 'UNI-359', 'UNI-360', 'UNI-361', 'UNI-362', 'UNI-363', 'UNI-364', 'UNI-365', 'UNI-366', 'UNI-367', 'UNI-368', 'UNI-369', 'UNI-370', 'UNI-371', 'UNI-372', 'UNI-373', 'UNI-374', 'UNI-375', 'UNI-376', 'UNI-377', 'UNI-378', 'UNI-379', 'UNI-380', 'UNI-381', 'UNI-382', 'UNI-383', 'UNI-384', 'UNI-385', 'UNI-386', 'UNI-387', 'UNI-388', 'UNI-389', 'UNI-390', 'UNI-391', 'UNI-392', 'UNI-393', 'UNI-394', 'UNI-395', 'UNI-396', 'UNI-397', 'UNI-398', 'UNI-399', 'UNI-400', 'UNI-401', 'UNI-402', 'UNI-403', 'UNI-404', 'UNI-405', 'UNI-406', 'UNI-407', 'UNI-408', 'UNI-409', 'UNI-410', 'UNI-411', 'UNI-412', 'UNI-413', 'UNI-414', 'UNI-415', 'UNI-416', 'UNI-417', 'UNI-418', 'UNI-419', 'UNI-420', 'UNI-421', 'UNI-422', 'UNI-423', 'UNI-424', 'UNI-425', 'UNI-426', 'UNI-427', 'UNI-428', 'UNI-429', 'UNI-430', 'UNI-431', 'UNI-432', 'UNI-433', 'UNI-434', 'UNI-435', 'UNI-436', 'UNI-437', 'UNI-438', 'UNI-439', 'UNI-440', 'UNI-441', 'UNI-442', 'UNI-443', 'UNI-444', 'UNI-445', 'UNI-446', 'UNI-447', 'UNI-448', 'UNI-449', 'UNI-450', 'UNI-451', 'UNI-452', 'UNI-453', 'UNI-454', 'UNI-455', 'UNI-456', 'UNI-457', 'UNI-458', 'UNI-459', 'UNI-460', 'UNI-461', 'UNI-462', 'UNI-463', 'UNI-464', 'UNI-465', 'UNI-466', 'UNI-467', 'UNI-468', 'UNI-469', 'UNI-470', 'UNI-471', 'UNI-472', 'UNI-473', 'UNI-474', 'UNI-475', 'UNI-476', 'UNI-477', 'UNI-478', 'UNI-479', 'UNI-480', 'UNI-481', 'UNI-482', 'UNI-483', 'UNI-484', 'UNI-485', 'UNI-486', 'UNI-487', 'UNI-488', 'UNI-489', 'UNI-490', 'UNI-491', 'UNI-492', 'UNI-493', 'UNI-494', 'UNI-495', 'UNI-496', 'UNI-497', 'UNI-498', 'UNI-499', 'UNI-500', 'UNI-501', 'UNI-502', 'UNI-503', 'UNI-504', 'UNI-505', 'UNI-506', 'UNI-507', 'UNI-508', 'UNI-509', 'UNI-510', 'UNI-511', 'UNI-512', 'UNI-513', 'UNI-514', 'UNI-515', 'UNI-516', 'UNI-517', 'UNI-518', 'UNI-519', 'UNI-520', 'UNI-521', 'UNI-522', 'UNI-523', 'UNI-524', 'UNI-525', 'UNI-526', 'UNI-527', 'UNI-528', 'UNI-529', 'UNI-530', 'UNI-531', 'UNI-532', 'UNI-533', 'UNI-534', 'UNI-535', 'UNI-536', 'UNI-537', 'UNI-538', 'UNI-539', 'UNI-540', 'UNI-541', 'UNI-542', 'UNI-543', 'UNI-544', 'UNI-545', 'UNI-546', 'UNI-547', 'UNI-548', 'UNI-549', 'UNI-550', 'UNI-551', 'UNI-552', 'UNI-553', 'UNI-554', 'UNI-555', 'UNI-556', 'UNI-557', 'UNI-558', 'UNI-559', 'UNI-560', 'UNI-561', 'UNI-562', 'UNI-563', 'UNI-564', 'UNI-565', 'UNI-566', 'UNI-567', 'UNI-568', 'UNI-569', 'UNI-570', 'UNI-571', 'UNI-572', 'UNI-573', 'UNI-574', 'UNI-575', 'UNI-576', 'UNI-577', 'UNI-578', 'UNI-579', 'UNI-580', 'UNI-581', 'UNI-582', 'UNI-583', 'UNI-584', 'UNI-585', 'UNI-586', 'UNI-587', 'UNI-588', 'UNI-589', 'UNI-590', 'UNI-591', 'UNI-592', 'UNI-593', 'UNI-594', 'UNI-595', 'UNI-596', 'UNI-597', 'UNI-598', 'UNI-599', 'UNI-600', 'UNI-601', 'UNI-602', 'UNI-603', 'UNI-604', 'UNI-605', 'UNI-606', 'UNI-607', 'UNI-608', 'UNI-609', 'UNI-610', 'UNI-611', 'UNI-612', 'UNI-613', 'UNI-614', 'UNI-615', 'UNI-616', 'UNI-617', 'UNI-618', 'UNI-619', 'UNI-620', 'UNI-621', 'UNI-622', 'UNI-623', 'UNI-624', 'UNI-625', 'UNI-626', 'UNI-627', 'UNI-628', 'UNI-629', 'UNI-630', 'UNI-631', 'UNI-632', 'UNI-633', 'UNI-634', 'UNI-635', 'UNI-636', 'UNI-637', 'UNI-638', 'UNI-639', 'UNI-640', 'UNI-641', 'UNI-642', 'UNI-643', 'UNI-644', 'UNI-645', 'UNI-646', 'UNI-647', 'UNI-648', 'UNI-649', 'UNI-650', 'UNI-651', 'UNI-652', 'UNI-653', 'UNI-654', 'UNI-655', 'UNI-656', 'UNI-657', 'UNI-658', 'UNI-659', 'UNI-660', 'UNI-661', 'UNI-662', 'UNI-663', 'UNI-664', 'UNI-665', 'UNI-666', 'UNI-667', 'UNI-668', 'UNI-669', 'UNI-670', 'UNI-671', 'UNI-672', 'UNI-673', 'UNI-674', 'UNI-675', 'UNI-676', 'UNI-677', 'UNI-678', 'UNI-679', 'UNI-680', 'UNI-681', 'UNI-682', 'UNI-683', 'UNI-684', 'UNI-685', 'UNI-686', 'UNI-687', 'UNI-688', 'UNI-689', 'UNI-690', 'UNI-691', 'UNI-692', 'UNI-693', 'UNI-694', 'UNI-695', 'UNI-696', 'UNI-697', 'UNI-698', 'UNI-699', 'UNI-700', 'UNI-701', 'UNI-702', 'UNI-703', 'UNI-704', 'UNI-705', 'UNI-706', 'UNI-707', 'UNI-708', 'UNI-709', 'UNI-710', 'UNI-711', 'UNI-712', 'UNI-713', 'UNI-714', 'UNI-715', 'UNI-716', 'UNI-717', 'UNI-718', 'UNI-719', 'UNI-720', 'UNI-721', 'UNI-722', 'UNI-723', 'UNI-724', 'UNI-725', 'UNI-726', 'UNI-727', 'UNI-728', 'UNI-729', 'UNI-730', 'UNI-731', 'UNI-732', 'UNI-733', 'UNI-734', 'UNI-735', 'UNI-736', 'UNI-737', 'UNI-738', 'UNI-739', 'UNI-740', 'UNI-741', 'UNI-742', 'UNI-743', 'UNI-744', 'UNI-745', 'UNI-746', 'UNI-747', 'UNI-748', 'UNI-749', 'UNI-750', 'UNI-751', 'UNI-752', 'UNI-753', 'UNI-754', 'UNI-755', 'UNI-756', 'UNI-757', 'UNI-758', 'UNI-759', 'UNI-760', 'UNI-761', 'UNI-762', 'UNI-763', 'UNI-764', 'UNI-765', 'UNI-766', 'UNI-767', 'UNI-768', 'UNI-769', 'UNI-770', 'UNI-771', 'UNI-772', 'UNI-773', 'UNI-774', 'UNI-775', 'UNI-776', 'UNI-777', 'UNI-778', 'UNI-779', 'UNI-780', 'UNI-781', 'UNI-782', 'UNI-783', 'UNI-784', 'UNI-785', 'UNI-786', 'UNI-787', 'UNI-788', 'UNI-789', 'UNI-790', 'UNI-791', 'UNI-792', 'UNI-793', 'UNI-794', 'UNI-795', 'UNI-796', 'UNI-797', 'UNI-798', 'UNI-799', 'UNI-800', 'UNI-801', 'UNI-802', 'UNI-803', 'UNI-804', 'UNI-805', 'UNI-806', 'UNI-807', 'UNI-808', 'UNI-809', 'UNI-810', 'UNI-811', 'UNI-812', 'UNI-813', 'UNI-814', 'UNI-815', 'UNI-816', 'UNI-817', 'UNI-818', 'UNI-819', 'UNI-820', 'UNI-821', 'UNI-822', 'UNI-823', 'UNI-824', 'UNI-825', 'UNI-826', 'UNI-827', 'UNI-828', 'UNI-829', 'UNI-830', 'UNI-831', 'UNI-832', 'UNI-833', 'UNI-834', 'UNI-835', 'UNI-836', 'UNI-837', 'UNI-838', 'UNI-839', 'UNI-840', 'UNI-841', 'UNI-842', 'UNI-843', 'UNI-844', 'UNI-845', 'UNI-846', 'UNI-847', 'UNI-848', 'UNI-849', 'UNI-850', 'UNI-851', 'UNI-852', 'UNI-853', 'UNI-854', 'UNI-855', 'UNI-856', 'UNI-857', 'UNI-858', 'UNI-859', 'UNI-860', 'UNI-861', 'UNI-862', 'UNI-863', 'UNI-864', 'UNI-865', 'UNI-866', 'UNI-867', 'UNI-868', 'UNI-869', 'UNI-870', 'UNI-871', 'UNI-872', 'UNI-873', 'UNI-874', 'UNI-875', 'UNI-876', 'UNI-877', 'UNI-878', 'UNI-879', 'UNI-880', 'UNI-881', 'UNI-882', 'UNI-883', 'UNI-884', 'UNI-885', 'UNI-886', 'UNI-887', 'UNI-888', 'UNI-889', 'UNI-890', 'UNI-891', 'UNI-892', 'UNI-893', 'UNI-894', 'UNI-895', 'UNI-896', 'UNI-897', 'UNI-898', 'UNI-899', 'UNI-900', 'UNI-901', 'UNI-902', 'UNI-903', 'UNI-904', 'UNI-905', 'UNI-906', 'UNI-907', 'UNI-908', 'UNI-909', 'UNI-910', 'UNI-911', 'UNI-912', 'UNI-913', 'UNI-914', 'UNI-915', 'UNI-916', 'UNI-917', 'UNI-918', 'UNI-919', 'UNI-920', 'UNI-921', 'UNI-922', 'UNI-923', 'UNI-924', 'UNI-925', 'UNI-926', 'UNI-927', 'UNI-928', 'UNI-929', 'UNI-930', 'UNI-931', 'UNI-932', 'UNI-933', 'UNI-934', 'UNI-935', 'UNI-936', 'UNI-937', 'UNI-938', 'UNI-939', 'UNI-940', 'UNI-941', 'UNI-942', 'UNI-943', 'UNI-944', 'UNI-945', 'UNI-946', 'UNI-947', 'UNI-948', 'UNI-949', 'UNI-950', 'UNI-951', 'UNI-952', 'UNI-953', 'UNI-954', 'UNI-955', 'UNI-956', 'UNI-957', 'UNI-958', 'UNI-959', 'UNI-960', 'UNI-961', 'UNI-962', 'UNI-963', 'UNI-964', 'UNI-965', 'UNI-966', 'UNI-967', 'UNI-968', 'UNI-969', 'UNI-970', 'UNI-971', 'UNI-972', 'UNI-973', 'UNI-974', 'UNI-975', 'UNI-976', 'UNI-977', 'UNI-978', 'UNI-979', 'UNI-980', 'UNI-981', 'UNI-982', 'UNI-983', 'UNI-984', 'UNI-985', 'UNI-986', 'UNI-987', 'UNI-988', 'UNI-989', 'UNI-990', 'UNI-991', 'UNI-992', 'UNI-993', 'UNI-994', 'UNI-995', 'UNI-996', 'UNI-997', 'UNI-998', 'UNI-999', 'UNI-1000', 'UNI-1001', 'UNI-1002', 'UNI-1003', 'UNI-1004', 'UNI-1005', 'UNI-1006', 'UNI-1007', 'UNI-1008', 'UNI-1009', 'UNI-1010', 'UNI-1011', 'UNI-1012', 'UNI-1013', 'UNI-1014', 'UNI-1015', 'UNI-1016', 'UNI-1017', 'UNI-1018', 'UNI-1019', 'UNI-1020', 'UNI-1021', 'UNI-1022', 'UNI-1023', 'UNI-1024', 'batch'\n",
       "    obsm: 'X_pca', 'X_umap', 'spatial', 'X_pca_neighbors_avg', 'X_pca_uni', 'X_pca_count'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdiva.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitSpatialDIVA(\n",
       "  (model): SpatialDIVA(\n",
       "    (px): px(\n",
       "      (fc_mu_x): Linear(in_features=64, out_features=3524, bias=True)\n",
       "      (fc_logvar_x): Linear(in_features=64, out_features=3524, bias=True)\n",
       "      (fc_mu_nb): Linear(in_features=64, out_features=3524, bias=True)\n",
       "      (fc_theta_nb): Linear(in_features=64, out_features=3524, bias=True)\n",
       "      (decoder_px): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=85, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pzd): pzd(\n",
       "      (fc_mu_d): Linear(in_features=128, out_features=5, bias=True)\n",
       "      (fc_logvar_d): Linear(in_features=128, out_features=5, bias=True)\n",
       "      (decoder_pzd): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pzy): ModuleList(\n",
       "      (0): pzy(\n",
       "        (fc_mu_y): Linear(in_features=128, out_features=20, bias=True)\n",
       "        (fc_logvar_y): Linear(in_features=128, out_features=20, bias=True)\n",
       "        (decoder_pzy): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=21, out_features=64, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): pzy(\n",
       "        (fc_mu_y): Linear(in_features=128, out_features=20, bias=True)\n",
       "        (fc_logvar_y): Linear(in_features=128, out_features=20, bias=True)\n",
       "        (decoder_pzy): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=50, out_features=64, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): pzy(\n",
       "        (fc_mu_y): Linear(in_features=128, out_features=20, bias=True)\n",
       "        (fc_logvar_y): Linear(in_features=128, out_features=20, bias=True)\n",
       "        (decoder_pzy): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (qzx): qzx(\n",
       "      (fc_mu_zx): Linear(in_features=64, out_features=20, bias=True)\n",
       "      (fc_logvar_zx): Linear(in_features=64, out_features=20, bias=True)\n",
       "      (encoder_qzx): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=3524, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (qzd): qzd(\n",
       "      (fc_mu_zd): Linear(in_features=64, out_features=5, bias=True)\n",
       "      (fc_logvar_zd): Linear(in_features=64, out_features=5, bias=True)\n",
       "      (encoder_qzd): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=3524, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (qzy): ModuleList(\n",
       "      (0-2): 3 x qzy(\n",
       "        (fc_mu_zy): Linear(in_features=64, out_features=20, bias=True)\n",
       "        (fc_logvar_zy): Linear(in_features=64, out_features=20, bias=True)\n",
       "        (encoder_qzy): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=3524, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (qd): qd(\n",
       "      (fc1): Linear(in_features=5, out_features=2, bias=True)\n",
       "    )\n",
       "    (qy): ModuleList(\n",
       "      (0): qy(\n",
       "        (fc1): Linear(in_features=20, out_features=21, bias=True)\n",
       "      )\n",
       "      (1): qy(\n",
       "        (fc1): Linear(in_features=20, out_features=50, bias=True)\n",
       "      )\n",
       "      (2): qy(\n",
       "        (fc1): Linear(in_features=20, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdiva.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialdiva-PyiMLd3V-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
