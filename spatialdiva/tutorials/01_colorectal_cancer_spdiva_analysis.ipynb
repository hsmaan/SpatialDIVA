{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up autoreload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll train the SpatialDIVA model on the Valdeolivas et al. colorectal cancer dataset, comprising of 12 slides of colorectal cancer tissue from different patients.\n",
    "\n",
    "For demonstration, we'll restrict the data to two slides for training of the model. After training, we'll extract embeddings from the different latent subspaces of SpatialDIVA, and analyze their covariance. We'll also examine how SpatialDIVA performs in terms of batch correction.\n",
    "\n",
    "We'll use the high-level SpatialDIVA API to train the model and extract embeddings.\n",
    "\n",
    "Let's start by loading the necessary modules and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc \n",
    "import anndata as ann \n",
    "\n",
    "from api import StDIVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by loading the anndata objects for Valdeolivas et al - in this case we'll restrict it to the first two files, corresponding to two slides.\n",
    "\n",
    "This data has been preprocessed such that spot-level deconvolution has been done, and pathologist annotations are also present in the data. UNI-feature extraction for the spot-level histpathology patches corresponding to the ST spots, has also been done. The appropriate features are stored in the `.obs` attribute of the anndata object, with the identifiers \"UNI\" before the feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first two slides of the Valdeolivas et al dataset\n",
    "adata_path = \"/scratch/hdd001/home/hmaan/visium_datasets/valdeolivas_hest_data\"\n",
    "adata_files = [f for f in os.listdir(adata_path) if f.endswith(\"processed.h5ad\")]\n",
    "adata_files = [os.path.join(adata_path, f) for f in adata_files]\n",
    "\n",
    "adata_files_sub = adata_files[:2]\n",
    "adatas = []\n",
    "for adata_file in adata_files_sub:\n",
    "    adata = sc.read_h5ad(adata_file)\n",
    "    adatas.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['array_row_x', 'array_col_x', 'pxl_col_in_fullres',\n",
       "       'pxl_row_in_fullres', 'in_tissue_x', 'pxl_row_in_fullres_old',\n",
       "       'pxl_col_in_fullres_old', 'n_genes_by_counts_x',\n",
       "       'log1p_n_genes_by_counts_x', 'total_counts_x',\n",
       "       ...\n",
       "       'UNI-1015', 'UNI-1016', 'UNI-1017', 'UNI-1018', 'UNI-1019', 'UNI-1020',\n",
       "       'UNI-1021', 'UNI-1022', 'UNI-1023', 'UNI-1024'],\n",
       "      dtype='object', length=1348)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas[0].obs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the UNI columns are at the end of the anndata obs attributes, followed by the other metadata. The format of this anndata object is such that each spot corresponds to one observation.\n",
    "\n",
    "The pathologist annotations per spot are stored in `.obs[\"Pathologist Annotation]`\n",
    "\n",
    "The maximally represented cell-type (after deconvolution) per spot is stored in `.obs[\"ST_celltype\"]`\n",
    "\n",
    "The batch/sample label is stored in `.obs[\"sample\"]`\n",
    "\n",
    "The positions of each spot on the slide are stored in `.obsm[\"spatial\"]`\n",
    "\n",
    "We'll need the following information for SpatialDIVA training - \n",
    "\n",
    "- The dimensionality of the UNI features\n",
    "- The dimensionality of the pathologist annotations (total number of classes)\n",
    "- The dimensionality of the batch/sample labels (total number of classes)\n",
    "- The dimensionality of the ST celltypes (total number of classes)\n",
    "- The dimensionality of the neighborhood context for each spot (50 dimensional by default)\n",
    "\n",
    "Let's go ahead and extract those from the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "counts_dim = 2500 # Because we are using 2500 HVGS in the processor later - the default\n",
    "uni_cols = [col for col in adatas[0].obs.columns if \"UNI\" in col]\n",
    "hist_dim = len(uni_cols)\n",
    "y1_dim = len(np.unique(adatas[0].obs[\"ST_celltype\"].values))\n",
    "y2_dim = 50\n",
    "\n",
    "# Transform path labels due to string encoding and character issues\n",
    "path_labels = adatas[0].obs[\"Pathologist Annotation\"].values\n",
    "le = LabelEncoder()\n",
    "path_labels = le.fit_transform(path_labels)\n",
    "\n",
    "y3_dim = len(np.unique(path_labels))\n",
    "d_dim = 2 # For two slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the data further here, or load it into the StDIVA API. This API will also take in the file locations, and perform relevant preprocessing steps (using the function `adata_process` - more information in the documentation). The API will also perform the training of the model, and extraction of embeddings.\n",
    "\n",
    "Let's go ahead and initialize the SpatialDIVA API with the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdiva = StDIVA(\n",
    "    counts_dim = counts_dim,\n",
    "    hist_dim = hist_dim,\n",
    "    y1_dim = y1_dim,\n",
    "    y2_dim = y2_dim,\n",
    "    y3_dim = y3_dim,\n",
    "    d_dim = d_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the data to the API in the form of a list of files corresponding to the anndata object with the information we've outlined above. \n",
    "\n",
    "We'll use 90% of the combined slides for training, and 10% for validation (the default split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/storage.py:85: ImplicitModificationWarning: X should not be a np.matrix, use np.ndarray instead.\n",
      "  warnings.warn(msg, ImplicitModificationWarning)\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "stdiva.add_data(\n",
    "    adata = adata_files[0:2],\n",
    "    label_key_y1 = \"ST_celltype\",\n",
    "    label_key_y3 = \"Pathologist Annotation\",\n",
    "    hist_col_key = \"UNI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can go ahead and train the model. The default number of epochs is 100, with early stopping enabled by default. Let's use these parameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-Pyi ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/h/hmaan/.cache/pypoetry/virtualenvs/spatialdiva-PyiMLd3V-py3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type        | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model | SpatialDIVA | 3.3 M  | train\n",
      "----------------------------------------------\n",
      "3.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 M     Total params\n",
      "13.148    Total estimated model params size (MB)\n",
      "110       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f879f87a025b4b02bb50ce3f5cf159c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdiva.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StDIVA' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstdiva\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StDIVA' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "stdiva.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialdiva-PyiMLd3V-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
